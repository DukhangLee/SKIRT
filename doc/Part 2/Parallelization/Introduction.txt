/**

\page ParallelizationIntroduction Introduction to Parallelization

\section TermsAndConcepts Terms and concepts

First, we define some software concepts that are absolutely essential for a basic understanding of parallelization:

 - A <b>thread</b> is a single flow of serial execution.
 - A <b>process</b> has one or more threads sharing the same logical memory. 
   Because they access the same memory, explicit \em locking is required to prevent race conditions.
 - A <b>program</b> has one or more processes, each which its own logical memory. Explicit \em communication between these processes is necessary.

Below, we define some hardware concepts.

 - A <b>processor</b> performs a single flow of serial execution.
 - A <b>node</b> has one or more processors sharing the same physical memory.
 - A <b>cluster</b> has one or more nodes, each with its own physical memory.

A process always resides on a single node, but a node can host multiple processes. So does a processor. 
Processes can (and have to) communicate through MPI whether they reside on the same processor, the same node or on a different node in the cluster.
Assuming that running more than one thread on a single processor at a particular moment is pointless, 
a node with \f$N\f$ processors can host at most \f$P\f$ processes with \f$N‚ÅÑP\f$ threads each. 
On the other hand, a node with physical memory size \f$M\f$ can host no more than \f$P\f$ processes with a memory requirement of \f$M/P\f$ each.

Assume each process needs a logical memory of size \f$D\f$ to fit the model. The node has a memory capacity of \f$M\f$. 
If \f$M/D<2\f$, only one model can fit on the node. Thus, irrespective of the number of processors, only one process can be run at a time. 
To make use of the multiple processors of the node, we must apply multithreading.
If \f$M/D \geq 2\f$, more than one process can be run on the node. The number of processes \f$P\f$ can actually be any number between 1 and \f$M/D\f$, 
with multiprocessing used to make sure that each processor executes threads.
It is however more efficient to always use the maximal number of processes \f$P=M/D\f$ (rounded down) in this case. 
This is because multi-processing scales better than multi-threading. Using multi-processing (MPI) will probably lead to the shortest execution time.
From the other perspective, where we want to maximize the size of our model, we can benefit from using multithreading. 
If there are \f$P\f$ processes, each with \f$T=N/P\f$ threads, the model size is limited to \f$D=M/P=T \times M/N \f$. 
Therefore, the maximum model size is reached for \f$T=N\f$ or \f$P=1\f$. In other words, using only one process on the node and a number of threads equal 
to the number of processors on that node permits the largest model size.

\section Assumptions Assumptions

The unit of parallelization in SKIRT is a chunk. A chunk is a certain number of photon packages of the same wavelength. 
Such a chunk is always simulated by a single thread. The total number of chunks is determined by the number of wavelengths in the 
simulation and the number of photon packages desired per wavelength. The parallelization of the oligochromatic and panchromatic simulations is 
designed in the same way: the \f$N_C \times N_{\lambda}\f$ chunks are distributed over the different threads, for different wavelengths at a time. 
The first chunks of each wavelength are handed out first. Whenever a thread has finished its work, it picks out a chunk of the wavelength that 
is next in line. The essence of a multithreaded parallelization is that the code executed by the different processors uses the same memory locations. 
The threads share the entire process state, with all variables and functions. This inevitably leads to so-called race conditions, 
where different threads want to read or write the same memory location at the same time. When one process acts on the value of a certain variable, 
during which another thread changes that same variable, inconsistencies occur. There are mechanisms that prevent this incorrect behaviour, 
such as locking. Locking basically means that all other threads are prevented from reading a certain variable 
until a certain thread has finished writing it. If used extensively however, with a large number of threads, 
this can ultimately lead to decreased performance.

With an MPI parallelization, the execution of parallel code is performed by multiple, independent processes, 
each with their own memory addresses and process state. This avoids the performance issues from which the multithreading suffers. 
On the other hand, this kind of parallelization requires the implementation of explicit calls to the MPI library at any point 
where communication is needed between processes: a process cannot just read the memory of an other process. 
If implemented efficiently with the minimal amount of communication, an MPI parallelized code scales much better with a 
high number of processors. This makes these codes perfectly suited for running on (distributed memory) multi-processor systems (or supercomputers). 

As each MPI process is basically a copy of the entire program, a program parallelized with \f$n\f$ parallel processes 
takes in \f$n\f$ times as much memory as the same program parallelized with n parallel threads. 
That could be a reason for choosing a multithreaded approach when the model size is too large (many wavelengths and/or a fine dust grid). 
When we talk about running a program with MPI, we of course assume the model fits on the system. 

We have implemented an MPI parallelization in SKIRT that follows the same design as the thread parallelization. 
That means: each process simulates all wavelengths, but each process simulates only a portion of the chunks. 
That will be the design presented in this text. In a later stage, if performance enhancements seem necessary, 
we can also choose to give each process only a limited amount of wavelengths. This procedure will minimize the communication overhead. 
Sometimes, wavelengths will however also need to be split over multiple processes if the number of processors exceeds the number of wavelengths.

*/
